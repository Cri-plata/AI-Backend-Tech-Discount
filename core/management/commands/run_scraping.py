from django.core.management.base import BaseCommand
from core.scrapping.alkosto.Crawling import AlkostoCrawler
from datetime import datetime


class Command(BaseCommand):
    help = 'Ejecuta el scraping completo de Alkosto'

    def add_arguments(self, parser):
        parser.add_argument(
            '--categories',
            nargs='+',
            help='Categor√≠as espec√≠ficas a scrapear (opcional)'
        )
        parser.add_argument(
            '--clicks',
            type=int,
            default=None,  # ‚Üê Por defecto None para todos los productos
            help='N√∫mero de clicks en "Mostrar m√°s" (None para todos)'
        )
        parser.add_argument(
            '--limit-categories',
            type=int,
            default=None,
            help='L√≠mite de categor√≠as a scrapear'
        )

    def handle(self, *args, **options):
        start_time = datetime.now()

        # Crear crawler con el par√°metro clicks
        crawler = AlkostoCrawler(clicks=options['clicks'])
        categories = options['categories']
        limit_categories = options['limit_categories']

        self.stdout.write(
            self.style.SUCCESS('üöÄ INICIANDO SCRAPING COMPLETO DE ALKOSTO')
        )

        if options['clicks'] is None:
            self.stdout.write("üî¢ MODO: TODOS los productos (clicks=None)")
        else:
            self.stdout.write(f"üî¢ MODO: {options['clicks']} clicks por categor√≠a")

        if categories:
            # Scrapear categor√≠as espec√≠ficas
            results = crawler.crawl_specific_categories(categories)
            total_products = sum(len(products) for products in results.values())
        else:
            # Scrapear todas las categor√≠as o limitar
            if limit_categories:
                # Limitar categor√≠as
                limited_urls = dict(list(crawler.category_urls.items())[:limit_categories])
                total_products = 0
                for category_name, url in limited_urls.items():
                    products = crawler.crawl_category(category_name, url)
                    total_products += len(products)
            else:
                # Todas las categor√≠as
                all_products = crawler.crawl_all_categories()
                total_products = len(all_products)

        # Estad√≠sticas
        end_time = datetime.now()
        execution_time = (end_time - start_time).total_seconds() / 60

        self.stdout.write(
            self.style.SUCCESS(f'\nüéâ SCRAPING COMPLETADO!')
        )
        self.stdout.write(f'‚è±Ô∏è  Tiempo total: {execution_time:.2f} minutos')
        self.stdout.write(f'üì¶ Total productos con descuento: {total_products}')

        # Verificar base de datos
        from core.mongo.MongoManager import MongoManager
        mongo = MongoManager()
        self.stdout.write(f'üìä Total en MongoDB: {mongo.get_product_count()} productos')
        self.stdout.write(f'üè∑Ô∏è  Categor√≠as: {", ".join(mongo.get_categories())}')